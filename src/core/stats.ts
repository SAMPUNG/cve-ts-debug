import { PRINT_INTERVAL, WS_OPEN_STATE, WS_TAG } from '@cve-ts/dictionary'
import { pc, updatePeerConnection, ws } from '@cve-ts/player'

import { setFrameDisplayDeltaTime } from './latency'
import refs from '../refs/instance'

let audioBitrate: number | undefined
let audioBytesReceived: number | undefined
let audioCodec: string | undefined
let avgBitrate: number | undefined
let avgframerate: number | undefined
let bitrate: number | undefined
let bytesReceivedStart: number | undefined
let bytesReceived: number | undefined
let codecs: Record<string, string> = {}
let currentRoundTripTime: number | undefined
let frameHeight: number | undefined
let frameHeightStart: number | undefined
let frameWidth: number | undefined
let frameWidthStart: number | undefined
let framerate: number | undefined
let framesDecoded: number | undefined
let framesDecodedStart: number | undefined
let framesDropped: number | undefined
let framesDroppedPercentage: number | undefined
let framesReceived: number | undefined
let highBitrate: number | undefined
let highFramerate: number | undefined
let lowBitrate: number | undefined
let lowFramerate: number | undefined
let nextPrintDuration: number = PRINT_INTERVAL
let packetsLost: number | undefined
let printStats: boolean
let receivedBytes: number
let receivedBytesMeasurement: string = 'B'
export let receiveToCompositeMs: number | undefined
let timer: NodeJS.Timer | null = null
let timestamp: number | undefined
let timestampStart: number | undefined
let videoCodec: string | undefined
export let videoEncoderQP: number

export function aggregateStats(checkInterval: number) {
  timer = setInterval(() => {
    pc?.getStats(null).then((stats: RTCStatsReport) => {
      onStats(stats)
    })
  }, checkInterval)
}

export function clear() {
  if (timer) {
    clearInterval(timer)
  }
}

export function close() {
  if (pc) {
    console.log('Closing existing peerClient')
    pc.close()
    updatePeerConnection()
  }
  clear()
}

function onAggregatedStats() {
  const numberFormat = new Intl.NumberFormat(window.navigator.language, {
    maximumFractionDigits: 0,
  })
  const timeFormat = new Intl.NumberFormat(window.navigator.language, {
    maximumFractionDigits: 0,
    minimumIntegerDigits: 2,
  })

  // Calculate duration of run
  let runTime = (timestamp! - timestampStart!) / 1000
  const timeValues = []
  const timeDurations = [60, 60]
  for (let timeIndex = 0; timeIndex < timeDurations.length; timeIndex++) {
    timeValues.push(runTime % timeDurations[timeIndex])
    runTime /= timeDurations[timeIndex]
  }
  timeValues.push(runTime)

  const runTimeSeconds = timeValues[0]
  const runTimeMinutes = Math.floor(timeValues[1])
  const runTimeHours = Math.floor(timeValues[2])

  receivedBytesMeasurement = 'B'
  receivedBytes = bytesReceived ?? 0
  const dataMeasurements = ['kB', 'MB', 'GB']
  for (let index = 0; index < dataMeasurements.length; index++) {
    if (receivedBytes < 100 * 1000) break
    receivedBytes /= 1000
    receivedBytesMeasurement = dataMeasurements[index]
  }

  // "blinks" quality status element for 1 sec by making it transparent, speed = number of blinks
  const blinkQualityStatus = (speed: number) => {
    let iter = speed
    let opacity = 1 // [0..1]
    const tickId = setInterval(
      () => {
        opacity -= 0.1
        // map `opacity` to [-0.5..0.5] range, decrement by 0.2 per step and take `abs` to make it blink: 1 -> 0 -> 1
        refs['quality-status'].style.opacity = Math.abs(
          (opacity - 0.5) * 2
        ).toString()
        if (opacity <= 0.1) {
          if (--iter === 0) {
            clearInterval(tickId)
          } else {
            // next blink
            opacity = 1
          }
        }
      },
      100 / speed // msecs
    )
  }

  const orangeQP = 26
  const redQP = 35

  let statsText = ''

  let color = 'lime'
  if (videoEncoderQP > redQP) {
    color = 'red'
    blinkQualityStatus(2)
    statsText += `<div style="color: ${color}">Bad network connection</div>`
  } else if (videoEncoderQP > orangeQP) {
    color = 'orange'
    blinkQualityStatus(1)
    statsText += `<div style="color: ${color}">Spotty network connection</div>`
  }

  refs['quality-status'].className = `${color}-status`

  statsText += `<div>Duration: ${timeFormat.format(
    runTimeHours
  )}:${timeFormat.format(runTimeMinutes)}:${timeFormat.format(
    runTimeSeconds
  )}</div>`
  statsText += `<div>Video Resolution: ${
    frameWidth && frameHeight ? `${frameWidth}x${frameHeight}` : 'Chrome only'
  }</div>`
  statsText += `<div>Received (${receivedBytesMeasurement}): ${numberFormat.format(
    receivedBytes
  )}</div>`
  statsText += `<div>Frames Decoded: ${
    framesDecoded ? numberFormat.format(framesDecoded!) : 'Chrome only'
  }</div>`
  statsText += `<div>Packets Lost: ${
    packetsLost ? numberFormat.format(packetsLost!) : 'Chrome only'
  }</div>`
  statsText += `<div style="color: ${color}">Bitrate (kbps): ${
    bitrate ? numberFormat.format(bitrate!) : 'Chrome only'
  }</div>`
  statsText += `<div>Framerate: ${
    framerate ? numberFormat.format(framerate!) : 'Chrome only'
  }</div>`
  statsText += `<div>Frames dropped: ${
    framesDropped ? numberFormat.format(framesDropped!) : 'Chrome only'
  }</div>`
  statsText += `<div>Net RTT (ms): ${
    currentRoundTripTime
      ? numberFormat.format(currentRoundTripTime! * 1000)
      : "Can't calculate"
  }</div>`
  statsText += `<div>Browser receive to composite (ms): ${
    receiveToCompositeMs
      ? numberFormat.format(receiveToCompositeMs!)
      : 'Chrome only'
  }</div>`
  statsText += `<div style="color: ${color}">Video Quantization Parameter: ${videoEncoderQP}</div>`

  const statsDiv = refs['stats']
  statsDiv.innerHTML = statsText

  if (printStats) {
    if (timestampStart) {
      if (timestamp! - timestampStart > nextPrintDuration) {
        if (ws?.readyState === WS_OPEN_STATE) {
          console.log(...WS_TAG, `-> SS: stats`)
          ws.send(
            JSON.stringify({
              type: 'stats',
              data: {
                audioBitrate,
                audioBytesReceived,
                audioCodec,
                avgBitrate,
                avgframerate,
                bitrate,
                bytesReceivedStart,
                bytesReceived,
                codecs,
                currentRoundTripTime,
                frameHeight,
                frameHeightStart,
                frameWidth,
                frameWidthStart,
                framerate,
                framesDecoded,
                framesDecodedStart,
                framesDropped,
                framesDroppedPercentage,
                framesReceived,
                highBitrate,
                highFramerate,
                lowBitrate,
                lowFramerate,
                nextPrintDuration,
                packetsLost,
                printStats,
                receivedBytes,
                receivedBytesMeasurement,
                receiveToCompositeMs,
                timer,
                timestamp,
                timestampStart,
                videoCodec,
                videoEncoderQP,
              },
            })
          )
        }
        nextPrintDuration += PRINT_INTERVAL
      }
    }
  }
}

function onStats(stats: RTCStatsReport) {
  codecs = {}

  stats.forEach((stat) => {
    // Get the inbound-rtp for video
    if (
      stat.type === 'inbound-rtp' &&
      !stat.isRemote &&
      (stat.mediaType === 'video' || stat.id.toLowerCase().includes('video'))
    ) {
      timestamp = stat.timestamp
      bytesReceived = stat.bytesReceived
      framesDecoded = stat.framesDecoded
      packetsLost = stat.packetsLost
      bytesReceivedStart = bytesReceivedStart
        ? bytesReceivedStart
        : stat.bytesReceived
      framesDecodedStart = framesDecodedStart
        ? framesDecodedStart
        : stat.framesDecoded
      timestampStart = timestampStart ? timestampStart : stat.timestamp

      if (timestamp) {
        // Get the mimetype of the video codec being used
        if (stat.codecId && codecs && codecs.hasOwnProperty(stat.codecId)) {
          videoCodec = codecs[stat.codecId]
        }

        if (bytesReceived) {
          // bitrate = bits received since last time / number of ms since last time
          //This is automatically in kbits (where k=1000) since time is in ms and stat we want is in seconds (so a '* 1000' then a '/ 1000' would negate each other)
          bitrate =
            (8 * (bytesReceived! - bytesReceived)) / (timestamp! - timestamp)
          bitrate = Math.floor(bitrate)
          lowBitrate = lowBitrate && lowBitrate < bitrate ? lowBitrate : bitrate
          highBitrate =
            highBitrate && highBitrate > bitrate ? highBitrate : bitrate
        }

        if (bytesReceivedStart) {
          avgBitrate =
            (8 * (bytesReceived! - bytesReceivedStart)) /
            (timestamp! - timestampStart!)
          avgBitrate = Math.floor(avgBitrate)
        }

        if (framesDecoded) {
          // framerate = frames decoded since last time / number of seconds since last time
          framerate =
            (framesDecoded! - framesDecoded) / ((timestamp! - timestamp) / 1000)
          framerate = Math.floor(framerate)
          lowFramerate =
            lowFramerate && lowFramerate < framerate ? lowFramerate : framerate
          highFramerate =
            highFramerate && highFramerate > framerate
              ? highFramerate
              : framerate
        }

        if (framesDecodedStart) {
          avgframerate =
            (framesDecoded! - framesDecodedStart) /
            ((timestamp! - timestampStart!) / 1000)
          avgframerate = Math.floor(avgframerate)
        }
      }
    }

    // Get inbound-rtp for audio
    if (
      stat.type === 'inbound-rtp' &&
      !stat.isRemote &&
      (stat.mediaType === 'audio' || stat.id.toLowerCase().includes('audio'))
    ) {
      // Get audio bytes received
      if (stat.bytesReceived) {
        audioBytesReceived = stat.bytesReceived
      }

      // As we loop back through we may wish to compute some stats based on a delta of the previous time we recorded the stat
      if (timestamp) {
        // Get the mimetype of the audio codec being used
        if (stat.codecId && codecs && codecs.hasOwnProperty(stat.codecId)) {
          audioCodec = codecs[stat.codecId]
        }

        // Determine audio bitrate delta over the time period
        if (audioBytesReceived) {
          audioBitrate =
            (8 * (audioBytesReceived! - audioBytesReceived)) /
            (stat.timestamp - timestamp)
          audioBitrate = Math.floor(audioBitrate)
        }
      }
    }

    //Read video track stats
    if (
      stat.type === 'track' &&
      (stat.trackIdentifier === 'video_label' || stat.kind === 'video')
    ) {
      framesDropped = stat.framesDropped
      framesReceived = stat.framesReceived
      framesDroppedPercentage = (stat.framesDropped / stat.framesReceived) * 100
      frameHeight = stat.frameHeight
      frameWidth = stat.frameWidth
      frameHeightStart = frameHeightStart ? frameHeightStart : stat.frameHeight
      frameWidthStart = frameWidthStart ? frameWidthStart : stat.frameWidth
    }

    if (
      stat.type === 'candidate-pair' &&
      stat.hasOwnProperty('currentRoundTripTime') &&
      stat.currentRoundTripTime != 0
    ) {
      currentRoundTripTime = stat.currentRoundTripTime
    }

    // Store mimetype of each codec
    if (stat.type === 'codec' && stat.mimeType && stat.id) {
      const codecId = stat.id
      const codecType = stat.mimeType
        .replace('video/', '')
        .replace('audio/', '')
      codecs[codecId] = codecType
    }
  })

  if (receiveToCompositeMs) {
    setFrameDisplayDeltaTime(receiveToCompositeMs)
  }

  onAggregatedStats()
}

export function updateReceiveToCompositeMs(value: number) {
  receivedBytes = value
}

export function updateVideoEncoderQP(value: number) {
  videoEncoderQP = value
}
